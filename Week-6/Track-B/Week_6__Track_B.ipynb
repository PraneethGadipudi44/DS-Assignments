{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, re, json\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from pathlib import Path\n",
        "\n",
        "GRAPHML = Path(\"graph_week6.graphml\")\n",
        "EDGELIST = Path(\"graph_week6.edgelist\")\n",
        "ENTITIES_CSV = Path(\"entities.csv\")\n",
        "RELATIONS_CSV = Path(\"relations.csv\")\n",
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "def load_from_graphml(p: Path):\n",
        "    try:\n",
        "        g = nx.read_graphml(p)\n",
        "        GG = nx.Graph()\n",
        "        for n, d in g.nodes(data=True):\n",
        "            GG.add_node(str(n), **{k: d[k] for k in d})\n",
        "        for u, v, d in g.edges(data=True):\n",
        "            GG.add_edge(str(u), str(v), **{k: d[k] for k in d})\n",
        "        return GG\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def load_from_edgelist(p: Path):\n",
        "    try:\n",
        "        g = nx.read_edgelist(str(p))\n",
        "        return g\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def load_from_entities_relations(ents: Path, rels: Path):\n",
        "    try:\n",
        "        df_e = pd.read_csv(ents)\n",
        "        df_r = pd.read_csv(rels)\n",
        "        g = nx.Graph()\n",
        "        for _, r in df_e.iterrows():\n",
        "            g.add_node(str(r[\"entity\"]), type=str(r.get(\"type\", \"\")))\n",
        "        for _, r in df_r.iterrows():\n",
        "            g.add_edge(\n",
        "                str(r[\"head\"]), str(r[\"tail\"]),\n",
        "                doc_id=str(r.get(\"doc_id\", \"?\")),\n",
        "                sentence=str(r.get(\"sentence\", \"\")),\n",
        "            )\n",
        "        return g\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "loaded = None\n",
        "if GRAPHML.exists():\n",
        "    loaded = load_from_graphml(GRAPHML)\n",
        "elif EDGELIST.exists():\n",
        "    loaded = load_from_edgelist(EDGELIST)\n",
        "elif ENTITIES_CSV.exists() and RELATIONS_CSV.exists():\n",
        "    loaded = load_from_entities_relations(ENTITIES_CSV, RELATIONS_CSV)\n",
        "\n",
        "if loaded is None:\n",
        "    G = nx.Graph()\n",
        "    nodes = [(\"Method X\",\"METHOD\"),(\"Author A\",\"AUTHOR\"),(\"Dataset D1\",\"DATASET\"),(\"Paper P3\",\"PAPER\"),(\"Metric F1\",\"METRIC\")]\n",
        "    for n,t in nodes: G.add_node(n, type=t)\n",
        "    G.add_edge(\"Method X\",\"Author A\",  doc_id=\"doc1\", sentence=\"Method X was introduced by Author A.\")\n",
        "    G.add_edge(\"Method X\",\"Dataset D1\",doc_id=\"doc1\", sentence=\"Method X was evaluated on Dataset D1 with F1=0.78.\")\n",
        "    G.add_edge(\"Method X\",\"Paper P3\",  doc_id=\"doc4\", sentence=\"Paper P3 applies Method X to Dataset D2 and reports Accuracy 0.82.\")\n",
        "else:\n",
        "    G = loaded\n",
        "\n",
        "print(f\"✅ Graph loaded: {len(G.nodes())} nodes, {len(G.edges())} edges\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVbW038M5cb8",
        "outputId": "cf603882-86d6-43f0-9428-b08e9d98c6ef"
      },
      "id": "lVbW038M5cb8",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Graph loaded: 5 nodes, 3 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def node_type(n: str):\n",
        "    t = G.nodes[n].get(\"type\")\n",
        "    if t: return t\n",
        "    if re.search(r\"^Method\\s+[A-Z]\", n):  return \"METHOD\"\n",
        "    if re.search(r\"^Author\\s+[A-Z]\", n):  return \"AUTHOR\"\n",
        "    if re.search(r\"^Dataset\\s+[A-Z0-9]+\", n): return \"DATASET\"\n",
        "    if re.search(r\"^(Paper|Survey)\\s+[A-Z0-9]+\", n): return \"PAPER\"\n",
        "    if re.search(r\"(F1|Accuracy|AUC)\\b\", n): return \"METRIC\"\n",
        "    return \"ENTITY\"\n",
        "\n",
        "def neighbors_with_evidence(n: str):\n",
        "    out = []\n",
        "    if n not in G: return out\n",
        "    for u, v, data in G.edges(n, data=True):\n",
        "        nb = v if u == n else u\n",
        "        out.append({\n",
        "            \"neighbor\": nb,\n",
        "            \"neighbor_type\": node_type(nb),\n",
        "            \"doc_id\": data.get(\"doc_id\", \"?\"),\n",
        "            \"sentence\": data.get(\"sentence\", \"\")\n",
        "        })\n",
        "    return out\n",
        "\n",
        "def detect_method_from_query(q: str):\n",
        "    ql = (q or \"\").lower()\n",
        "    for n in G.nodes():\n",
        "        if node_type(n) == \"METHOD\" and n.lower() in ql:\n",
        "            return n\n",
        "    m = re.search(r\"\\bmethod\\s+([a-z0-9]+)\\b\", ql)\n",
        "    if m:\n",
        "        last = m.group(1).upper()\n",
        "        for n in G.nodes():\n",
        "            if node_type(n) == \"METHOD\" and n.split()[-1].upper() == last:\n",
        "                return n\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "-XBrbeVm5eWT"
      },
      "id": "-XBrbeVm5eWT",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decompose(query: str):\n",
        "    q = (query or \"\").lower()\n",
        "\n",
        "    if \"which author\" in q and \"which dataset\" in q:\n",
        "        return [\n",
        "            \"Who proposed the mentioned method?\",\n",
        "            \"Which dataset was that method evaluated on?\"\n",
        "        ]\n",
        "\n",
        "    if (\"introduced\" in q or \"proposed\" in q) and \"method\" in q and \"dataset\" in q:\n",
        "        return [\n",
        "            \"Which paper or author introduced the method?\",\n",
        "            \"Which dataset did that method/paper use for F1 or evaluation?\"\n",
        "        ]\n",
        "\n",
        "    return [query]\n"
      ],
      "metadata": {
        "id": "HCHEODV25gjD"
      },
      "id": "HCHEODV25gjD",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_subq(subq: str, memory: dict):\n",
        "    method = memory.get(\"method\") or detect_method_from_query(memory.get(\"root_query\",\"\")) or detect_method_from_query(subq)\n",
        "\n",
        "    if (\"author\" in subq.lower() or \"who proposed\" in subq.lower()) and method:\n",
        "        ev = neighbors_with_evidence(method)\n",
        "        authors = [e for e in ev if e[\"neighbor_type\"] == \"AUTHOR\"]\n",
        "        if authors:\n",
        "            ans = \"; \".join(sorted({a[\"neighbor\"] for a in authors}))\n",
        "            return {\"subq\": subq, \"answer\": ans, \"evidence\": authors, \"memory_update\": {\"author\": ans, \"method\": method}}\n",
        "\n",
        "    if (\"which dataset\" in subq.lower() or \"dataset\" in subq.lower()) and method:\n",
        "        ev = neighbors_with_evidence(method)\n",
        "        dsets = [e for e in ev if e[\"neighbor_type\"] == \"DATASET\"]\n",
        "        if dsets:\n",
        "            ans = \"; \".join(sorted({d[\"neighbor\"] for d in dsets}))\n",
        "            return {\"subq\": subq, \"answer\": ans, \"evidence\": dsets, \"memory_update\": {\"dataset\": ans, \"method\": method}}\n",
        "\n",
        "    if method:\n",
        "        ev = neighbors_with_evidence(method)\n",
        "        ans = \" ; \".join(sorted({f\"{e['neighbor']} ({e['neighbor_type']})\" for e in ev})) or \"No direct evidence.\"\n",
        "        return {\"subq\": subq, \"answer\": ans, \"evidence\": ev, \"memory_update\": {\"method\": method}}\n",
        "\n",
        "    return {\"subq\": subq, \"answer\": \"No evidence found in graph.\", \"evidence\": [], \"memory_update\": {}}\n"
      ],
      "metadata": {
        "id": "YWgV7VOh5ihx"
      },
      "id": "YWgV7VOh5ihx",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_hop(query: str):\n",
        "    subs = decompose(query)\n",
        "    memory = {\"root_query\": query}\n",
        "    hops = []\n",
        "    for s in subs:\n",
        "        h = answer_subq(s, memory)\n",
        "        hops.append(h)\n",
        "        memory.update(h.get(\"memory_update\", {}))\n",
        "\n",
        "    final = \" ; \".join(h[\"answer\"] for h in hops if h[\"answer\"])\n",
        "    citations = sorted({\n",
        "        ev.get(\"doc_id\") for h in hops for ev in h.get(\"evidence\", []) if ev.get(\"doc_id\")\n",
        "    })\n",
        "\n",
        "    return {\"query\": query, \"subqs\": subs, \"hops\": hops, \"final\": final, \"citations\": citations, \"memory\": memory}\n",
        "\n",
        "q1 = \"Which author proposed Method X, and which dataset did they evaluate it on?\"\n",
        "out1 = multi_hop(q1)\n",
        "\n",
        "q2 = \"Which dataset did the paper that introduced Method X use for F1?\"\n",
        "out2 = multi_hop(q2)\n",
        "\n",
        "out1, out2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_34CH5U5lJn",
        "outputId": "b6203c18-930c-4c03-e927-9528adf0e7b1"
      },
      "id": "a_34CH5U5lJn",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'query': 'Which author proposed Method X, and which dataset did they evaluate it on?',\n",
              "  'subqs': ['Who proposed the mentioned method?',\n",
              "   'Which dataset was that method evaluated on?'],\n",
              "  'hops': [{'subq': 'Who proposed the mentioned method?',\n",
              "    'answer': 'Author A',\n",
              "    'evidence': [{'neighbor': 'Author A',\n",
              "      'neighbor_type': 'AUTHOR',\n",
              "      'doc_id': 'doc1',\n",
              "      'sentence': 'Method X was introduced by Author A.'}],\n",
              "    'memory_update': {'author': 'Author A', 'method': 'Method X'}},\n",
              "   {'subq': 'Which dataset was that method evaluated on?',\n",
              "    'answer': 'Dataset D1',\n",
              "    'evidence': [{'neighbor': 'Dataset D1',\n",
              "      'neighbor_type': 'DATASET',\n",
              "      'doc_id': 'doc1',\n",
              "      'sentence': 'Method X was evaluated on Dataset D1 with F1=0.78.'}],\n",
              "    'memory_update': {'dataset': 'Dataset D1', 'method': 'Method X'}}],\n",
              "  'final': 'Author A ; Dataset D1',\n",
              "  'citations': ['doc1'],\n",
              "  'memory': {'root_query': 'Which author proposed Method X, and which dataset did they evaluate it on?',\n",
              "   'author': 'Author A',\n",
              "   'method': 'Method X',\n",
              "   'dataset': 'Dataset D1'}},\n",
              " {'query': 'Which dataset did the paper that introduced Method X use for F1?',\n",
              "  'subqs': ['Which paper or author introduced the method?',\n",
              "   'Which dataset did that method/paper use for F1 or evaluation?'],\n",
              "  'hops': [{'subq': 'Which paper or author introduced the method?',\n",
              "    'answer': 'Author A',\n",
              "    'evidence': [{'neighbor': 'Author A',\n",
              "      'neighbor_type': 'AUTHOR',\n",
              "      'doc_id': 'doc1',\n",
              "      'sentence': 'Method X was introduced by Author A.'}],\n",
              "    'memory_update': {'author': 'Author A', 'method': 'Method X'}},\n",
              "   {'subq': 'Which dataset did that method/paper use for F1 or evaluation?',\n",
              "    'answer': 'Dataset D1',\n",
              "    'evidence': [{'neighbor': 'Dataset D1',\n",
              "      'neighbor_type': 'DATASET',\n",
              "      'doc_id': 'doc1',\n",
              "      'sentence': 'Method X was evaluated on Dataset D1 with F1=0.78.'}],\n",
              "    'memory_update': {'dataset': 'Dataset D1', 'method': 'Method X'}}],\n",
              "  'final': 'Author A ; Dataset D1',\n",
              "  'citations': ['doc1'],\n",
              "  'memory': {'root_query': 'Which dataset did the paper that introduced Method X use for F1?',\n",
              "   'author': 'Author A',\n",
              "   'method': 'Method X',\n",
              "   'dataset': 'Dataset D1'}})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trace(out):\n",
        "    print(\"Query:\", out[\"query\"])\n",
        "    print(\"Final Answer:\", out[\"final\"])\n",
        "    print(\"Citations:\", \", \".join(out[\"citations\"]) if out[\"citations\"] else \"(none)\")\n",
        "    for i, h in enumerate(out[\"hops\"], 1):\n",
        "        print(f\"\\nHop {i}: {h['subq']}\\n -> {h['answer']}\")\n",
        "        for ev in h.get(\"evidence\", [])[:3]:\n",
        "            print(\"    -\", ev.get(\"doc_id\",\"?\"), \":\", ev.get(\"sentence\",\"\")[:140])\n",
        "\n",
        "print_trace(out1)\n",
        "print_trace(out2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH8DbFw15nbX",
        "outputId": "5e15bf85-fbe1-42e0-c00e-136c0caf14c2"
      },
      "id": "XH8DbFw15nbX",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Which author proposed Method X, and which dataset did they evaluate it on?\n",
            "Final Answer: Author A ; Dataset D1\n",
            "Citations: doc1\n",
            "\n",
            "Hop 1: Who proposed the mentioned method?\n",
            " -> Author A\n",
            "    - doc1 : Method X was introduced by Author A.\n",
            "\n",
            "Hop 2: Which dataset was that method evaluated on?\n",
            " -> Dataset D1\n",
            "    - doc1 : Method X was evaluated on Dataset D1 with F1=0.78.\n",
            "Query: Which dataset did the paper that introduced Method X use for F1?\n",
            "Final Answer: Author A ; Dataset D1\n",
            "Citations: doc1\n",
            "\n",
            "Hop 1: Which paper or author introduced the method?\n",
            " -> Author A\n",
            "    - doc1 : Method X was introduced by Author A.\n",
            "\n",
            "Hop 2: Which dataset did that method/paper use for F1 or evaluation?\n",
            " -> Dataset D1\n",
            "    - doc1 : Method X was evaluated on Dataset D1 with F1=0.78.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime, sys, platform, json\n",
        "\n",
        "cfg = {\n",
        "  \"timestamp\": datetime.datetime.now().isoformat(timespec=\"seconds\"),\n",
        "  \"graph\": {\"nodes\": len(G.nodes()), \"edges\": len(G.edges())},\n",
        "  \"engine\": {\"strategy\": \"self-ask\", \"hop_limit\": len(out1[\"hops\"])},\n",
        "  \"artifacts_used\": {\n",
        "      \"graphml\": str(GRAPHML) if GRAPHML.exists() else None,\n",
        "      \"edgelist\": str(EDGELIST) if EDGELIST.exists() else None,\n",
        "      \"entities_csv\": str(ENTITIES_CSV) if ENTITIES_CSV.exists() else None,\n",
        "      \"relations_csv\": str(RELATIONS_CSV) if RELATIONS_CSV.exists() else None,\n",
        "  }\n",
        "}\n",
        "json.dump(cfg, open(\"trackB_multihop_run_config.json\",\"w\"), indent=2)\n",
        "print(\"Saved: trackB_multihop_run_config.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n037D4Mp5q_3",
        "outputId": "542ae4cb-277f-4261-ec36-3f9a972ddac3"
      },
      "id": "n037D4Mp5q_3",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: trackB_multihop_run_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQ9YF2is5udN"
      },
      "id": "SQ9YF2is5udN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}