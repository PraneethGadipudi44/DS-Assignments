{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64edeed9",
      "metadata": {
        "id": "64edeed9"
      },
      "source": [
        "# Week 6 — Streamlit App (Graph-RAG + Multi-Hop)\n",
        "**Goal:** Expose your advanced pipeline via a simple web app.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install streamlit pyngrok networkx pandas numpy matplotlib pyyaml\n"
      ],
      "metadata": {
        "id": "Zj1Mrqv6-K-A"
      },
      "id": "Zj1Mrqv6-K-A",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, textwrap, time, pathlib\n",
        "APP_DIR = \"app_week6_streamlit\"\n",
        "os.makedirs(APP_DIR, exist_ok=True)\n",
        "\n",
        "APP_CODE = r'''import os, time, json, io\n",
        "import streamlit as st\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "st.set_page_config(page_title=\"Week 6: Next-Level RAG\", layout=\"wide\")\n",
        "st.title(\"Week 6 • Graph-RAG + Multi-Hop Demo\")\n",
        "\n",
        "# -----------------------------\n",
        "# 0) Load graph artifacts\n",
        "# -----------------------------\n",
        "def load_graph():\n",
        "    \"\"\"\n",
        "    Tries to load, in this order:\n",
        "    - ./graph_week6.graphml\n",
        "    - ./graph_week6.edgelist (expects 'u v' per line, evidence not required)\n",
        "    - demo tiny graph if nothing is available\n",
        "    \"\"\"\n",
        "    # Search current dir first, then app dir\n",
        "    CAND_ROOTS = [\".\", os.path.dirname(__file__)]\n",
        "    gml, edgelist = None, None\n",
        "    for root in CAND_ROOTS:\n",
        "        p = os.path.join(root, \"graph_week6.graphml\")\n",
        "        if os.path.exists(p):\n",
        "            gml = p; break\n",
        "    if gml is None:\n",
        "        for root in CAND_ROOTS:\n",
        "            p = os.path.join(root, \"graph_week6.edgelist\")\n",
        "            if os.path.exists(p):\n",
        "                edgelist = p; break\n",
        "\n",
        "    if gml:\n",
        "        try:\n",
        "            G = nx.read_graphml(gml)\n",
        "            src = \"graphml\"\n",
        "            return G, src\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Could not read {gml}: {e}\")\n",
        "\n",
        "    if edgelist:\n",
        "        try:\n",
        "            G = nx.read_edgelist(edgelist)\n",
        "            src = \"edgelist\"\n",
        "            return G, src\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Could not read {edgelist}: {e}\")\n",
        "\n",
        "    # Demo fallback (same spirit as professor’s examples)\n",
        "    G = nx.Graph()\n",
        "    nodes = [(\"Method X\",\"METHOD\"),(\"Author A\",\"AUTHOR\"),(\"Dataset D1\",\"DATASET\"),\n",
        "             (\"Paper P3\",\"PAPER\"),(\"Metric F1\",\"METRIC\")]\n",
        "    for n,t in nodes: G.add_node(n, type=t)\n",
        "    # attach evidence on edges as attributes\n",
        "    G.add_edge(\"Method X\",\"Author A\",  doc_id=\"doc1\", sentence=\"Method X was introduced by Author A.\")\n",
        "    G.add_edge(\"Method X\",\"Dataset D1\",doc_id=\"doc1\", sentence=\"Method X compared on Dataset D1 with F1=0.78.\")\n",
        "    G.add_edge(\"Method X\",\"Paper P3\",  doc_id=\"doc4\", sentence=\"Paper P3 applies Method X to D2 and reports Accuracy 0.82.\")\n",
        "    G.add_edge(\"Dataset D1\",\"Metric F1\",doc_id=\"doc1\", sentence=\"F1 reported for D1.\")\n",
        "    return G, \"demo\"\n",
        "\n",
        "G, GRAPH_SRC = load_graph()\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"Settings\")\n",
        "    mode = st.selectbox(\"Mode\", [\"Graph-RAG\",\"Multi-Hop\"], index=1)\n",
        "    hops = st.slider(\"Hop limit (Graph-RAG)\", 1, 3, 2, 1)\n",
        "    max_spans = st.slider(\"Top-k spans (Graph-RAG)\", 4, 20, 12, 1)\n",
        "    show_graph = st.checkbox(\"Show neighborhood graph\", value=True)\n",
        "\n",
        "st.caption(f\"Graph loaded: {len(G.nodes())} nodes, {len(G.edges())} edges (source: {GRAPH_SRC})\")\n",
        "\n",
        "# Optional tables if user placed these near the app\n",
        "def try_read_csv(name):\n",
        "    for root in [\".\", os.path.dirname(__file__)]:\n",
        "        p = os.path.join(root, name)\n",
        "        if os.path.exists(p):\n",
        "            try:\n",
        "                return pd.read_csv(p)\n",
        "            except Exception:\n",
        "                pass\n",
        "    return None\n",
        "\n",
        "entities_df  = try_read_csv(\"entities.csv\")   # optional, for quick inspection\n",
        "relations_df = try_read_csv(\"relations.csv\")  # optional, for quick inspection\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Graph-RAG utilities\n",
        "# -----------------------------\n",
        "def detect_seed_entities(query: str):\n",
        "    seeds = []\n",
        "    qlow = (query or \"\").lower()\n",
        "    for n in G.nodes():\n",
        "        if n.lower().split()[-1] in qlow:\n",
        "            seeds.append(n)\n",
        "    # also match type words in query\n",
        "    for n, data in G.nodes(data=True):\n",
        "        t = (data.get(\"type\") or \"\").lower()\n",
        "        if t and t in qlow:\n",
        "            seeds.append(n)\n",
        "    # dedupe, preserve order\n",
        "    seen = set(); out=[]\n",
        "    for s in seeds:\n",
        "        if s not in seen:\n",
        "            seen.add(s); out.append(s)\n",
        "    return out\n",
        "\n",
        "def neighborhood_evidence(seeds, hops=1, max_spans=12):\n",
        "    spans, seen_edges = [], set()\n",
        "    for s in seeds:\n",
        "        if s not in G:\n",
        "            continue\n",
        "        nodes = nx.single_source_shortest_path_length(G, s, cutoff=hops).keys()\n",
        "        for u in nodes:\n",
        "            for v in G.neighbors(u):\n",
        "                e = tuple(sorted([u, v]))\n",
        "                if e in seen_edges:\n",
        "                    continue\n",
        "                seen_edges.add(e)\n",
        "                data = G.get_edge_data(u, v) or {}\n",
        "                spans.append({\n",
        "                    \"u\": u, \"v\": v,\n",
        "                    \"doc_id\":   data.get(\"doc_id\", \"\"),\n",
        "                    \"sentence\": data.get(\"sentence\", f\"{u} — {v}\")\n",
        "                })\n",
        "                if len(spans) >= max_spans:\n",
        "                    return spans\n",
        "    return spans\n",
        "\n",
        "def graph_rag(query: str, hops=1, max_spans=12):\n",
        "    t0 = time.perf_counter()\n",
        "    seeds = detect_seed_entities(query)\n",
        "    spans = neighborhood_evidence(seeds, hops=hops, max_spans=max_spans)\n",
        "    # synthesize a tiny textual answer (LLM could be used here)\n",
        "    if spans:\n",
        "        answer = \"Based on neighborhood evidence: \" + \"; \".join(\n",
        "            f\"({s['doc_id']}) {s['sentence']}\" if s['doc_id'] else s['sentence']\n",
        "            for s in spans[:2]\n",
        "        )\n",
        "    else:\n",
        "        answer = \"No evidence found in graph.\"\n",
        "    return {\n",
        "        \"seeds\": seeds, \"spans\": spans, \"answer\": answer,\n",
        "        \"latency\": round(time.perf_counter() - t0, 3)\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Multi-hop (self-ask style)\n",
        "# -----------------------------\n",
        "def decompose(query: str):\n",
        "    q = (query or \"\").lower()\n",
        "    # tiny hand-made patterns that line up with our demo graph\n",
        "    if \"method x\" in q and (\"dataset\" in q or \"f1\" in q):\n",
        "        return [\"Which paper or author introduced the method?\",\n",
        "                \"Which dataset did that method/paper use for F1 or evaluation?\"]\n",
        "    return [query]\n",
        "\n",
        "def neighbors_for(node):\n",
        "    spans=[]\n",
        "    if node not in G: return spans\n",
        "    for u, v, data in G.edges(node, data=True):\n",
        "        spans.append({\"doc_id\": data.get(\"doc_id\",\"\"), \"sentence\": data.get(\"sentence\",\"\")})\n",
        "    return spans\n",
        "\n",
        "def answer_subq(subq, memory):\n",
        "    s = (subq or \"\").lower()\n",
        "    # Hop 1\n",
        "    if \"introduced the method\" in s:\n",
        "        ev = neighbors_for(\"Method X\")\n",
        "        ans = \"\"\n",
        "        # pick a paper/author if present in evidence\n",
        "        for e in ev:\n",
        "            line = e[\"sentence\"].lower()\n",
        "            if \"introduced\" in line and \"author\" in line:\n",
        "                ans = \"Author A\"\n",
        "                break\n",
        "            if \"paper\" in line or \"p3\" in line:\n",
        "                ans = \"Paper P3\"\n",
        "        ans = ans or \"Paper P3\"  # default if ambiguous\n",
        "        return {\"subq\": subq, \"answer\": ans, \"evidence\": ev, \"memory_update\": {\"intro_ref\": ans}}\n",
        "\n",
        "    # Hop 2\n",
        "    if \"dataset\" in s and (\"method\" in s or \"paper\" in s):\n",
        "        # see previous hop memory\n",
        "        ref = memory.get(\"intro_ref\",\"Method X\")\n",
        "        # two quick checks for demo\n",
        "        if ref in [\"Method X\",\"Paper P3\",\"Author A\"]:\n",
        "            ev = neighbors_for(\"Dataset D1\")\n",
        "            ans = \"Dataset D1\" if ev else \"\"\n",
        "            return {\"subq\": subq, \"answer\": ans, \"evidence\": ev, \"memory_update\": {}}\n",
        "\n",
        "    # Fallback\n",
        "    return {\"subq\": subq, \"answer\": \"\", \"evidence\": [], \"memory_update\": {}}\n",
        "\n",
        "def multi_hop(query: str, hops_limit=2):\n",
        "    t0 = time.perf_counter()\n",
        "    subs = decompose(query)[:hops_limit]\n",
        "    memory = {}\n",
        "    hops = []\n",
        "    trace = [(\"decompose\", f\"{len(subs)} hops\")]\n",
        "    for s in subs:\n",
        "        h = answer_subq(s, memory)\n",
        "        hops.append(h)\n",
        "        memory.update(h.get(\"memory_update\", {}))\n",
        "    final = \" ; \".join([h[\"answer\"] for h in hops if h[\"answer\"]]) or \"No evidence found in graph.\"\n",
        "    cites = sorted(set([e[\"doc_id\"] for h in hops for e in h.get(\"evidence\",[]) if e.get(\"doc_id\")]))\n",
        "    return {\n",
        "        \"final\": final, \"subqs\": subs, \"hops\": hops,\n",
        "        \"citations\": cites, \"trace\": trace,\n",
        "        \"latency\": round(time.perf_counter() - t0, 3)\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# 3) UI\n",
        "# -----------------------------\n",
        "q = st.text_area(\"Ask a question:\", \"Which dataset did the paper that introduced Method X use for F1?\")\n",
        "run = st.button(\"Run\")\n",
        "\n",
        "if run and q.strip():\n",
        "    if mode == \"Graph-RAG\":\n",
        "        out = graph_rag(q, hops=hops, max_spans=max_spans)\n",
        "        st.subheader(\"Answer\")\n",
        "        st.write(out[\"answer\"])\n",
        "\n",
        "        st.markdown(\"**Evidence (spans)**\")\n",
        "        if out[\"spans\"]:\n",
        "            for s in out[\"spans\"]:\n",
        "                st.markdown(f\"- ({s['doc_id']}) {s['sentence']}\")\n",
        "        else:\n",
        "            st.caption(\"(none)\")\n",
        "\n",
        "        st.caption(f\"Latency: {out['latency']}s\")\n",
        "\n",
        "        if show_graph:\n",
        "            st.markdown(\"**Neighborhood graph (preview)**\")\n",
        "            pos = nx.spring_layout(G, seed=7)\n",
        "            type_to_color = {\"METHOD\":\"#6aa84f\",\"AUTHOR\":\"#3c78d8\",\"DATASET\":\"#cc0000\",\"PAPER\":\"#674ea7\",\"METRIC\":\"#e69138\"}\n",
        "            colors = [type_to_color.get(G.nodes[n].get('type',''), \"#999\") for n in G.nodes()]\n",
        "            fig, ax = plt.subplots(figsize=(6,4))\n",
        "            nx.draw(G, pos, with_labels=True, node_color=colors, node_size=900, font_size=9, edge_color=\"#bbb\", ax=ax)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "    else:\n",
        "        res = multi_hop(q, hops_limit=hops)\n",
        "        st.subheader(\"Final\")\n",
        "        st.write(res[\"final\"])\n",
        "\n",
        "        st.markdown(\"**Citations:** \" + (\", \".join(res[\"citations\"]) if res[\"citations\"] else \"(none)\"))\n",
        "        st.caption(f\"Latency: {res['latency']}s\")\n",
        "\n",
        "        with st.expander(\"Sub-questions & Evidence\", expanded=True):\n",
        "            for i, h in enumerate(res[\"hops\"], 1):\n",
        "                st.write(f\"**Hop {i}** — {h['subq']} → {h['answer'] or '(no answer)'}\")\n",
        "                if h.get(\"evidence\"):\n",
        "                    for ev in h[\"evidence\"][:3]:\n",
        "                        st.markdown(f\"- ({ev.get('doc_id','')}) {ev.get('sentence','')}\")\n",
        "                else:\n",
        "                    st.caption(\"(no evidence found in graph)\")\n",
        "\n",
        "        with st.expander(\"Trace\", expanded=False):\n",
        "            for tag, info in res[\"trace\"]:\n",
        "                st.write(f\"- {tag}: {info}\")\n",
        "\n",
        "# Optional quick look at artifacts (if present)\n",
        "if entities_df is not None or relations_df is not None:\n",
        "    st.divider()\n",
        "    st.subheader(\"Artifacts (optional)\")\n",
        "    tabs = st.tabs([\"entities.csv\",\"relations.csv\"])\n",
        "    with tabs[0]:\n",
        "        if entities_df is not None: st.dataframe(entities_df.head(50))\n",
        "        else: st.caption(\"entities.csv not found\")\n",
        "    with tabs[1]:\n",
        "        if relations_df is not None: st.dataframe(relations_df.head(50))\n",
        "        else: st.caption(\"relations.csv not found\")\n",
        "'''\n",
        "\n",
        "with open(os.path.join(APP_DIR, \"app.py\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(APP_CODE)\n",
        "\n",
        "# minimal requirements\n",
        "with open(os.path.join(APP_DIR, \"requirements.txt\"), \"w\") as f:\n",
        "    f.write(\"streamlit\\npyyaml\\nnetworkx\\npandas\\nnumpy\\nmatplotlib\\n\")\n",
        "\n",
        "print(\"✅ Wrote Streamlit app to\", APP_DIR)\n",
        "print(\"   Place your Track-A artifacts next to the app (or notebook):\")\n",
        "print(\"   - graph_week6.graphml OR graph_week6.edgelist\")\n",
        "print(\"   - entities.csv (optional)  - relations.csv (optional)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyNFEo_JEmDS",
        "outputId": "9fc8b83c-87f5-437a-adae-5257fdfbee35"
      },
      "id": "wyNFEo_JEmDS",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote Streamlit app to app_week6_streamlit\n",
            "   Place your Track-A artifacts next to the app (or notebook):\n",
            "   - graph_week6.graphml OR graph_week6.edgelist\n",
            "   - entities.csv (optional)  - relations.csv (optional)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pyngrok\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"33IJoNio3UT3SuZz8Fw1xJMejPO_4JGWgxA9XQXYPpgvzJXw2\"\n",
        "\n",
        "import os, time, subprocess, threading, re\n",
        "from pyngrok import ngrok\n",
        "\n",
        "def run_streamlit():\n",
        "    cmd = [\"streamlit\", \"run\", \"app_week6_streamlit/app.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"]\n",
        "    subprocess.run(cmd)\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "thread.start()\n",
        "time.sleep(2)\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(\"🔗 Public URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15LkNouvEraT",
        "outputId": "2eaf2a4e-9c3f-4fd3-a422-9c39a4f0bf4e"
      },
      "id": "15LkNouvEraT",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Public URL: https://lexical-bree-volubly.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HxQulSaLE4HE"
      },
      "id": "HxQulSaLE4HE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}